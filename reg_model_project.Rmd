---
title: "Modeling and prediction for movies"
output: 
  html_document: 
    fig_height: 4
    highlight: pygments
    theme: spacelab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
```

### Load data

```{r load-data}
load("movies.Rdata")
```



* * *

## Part 1: Data
There are 651 randomly sampled movies in the IMDB dataset. As random sampling was used and the sample size is sufficiently large, but obviously less than 10% of all movies on IMDB (there are 1,523,191 non-TV episode titles according to these database statistics: http://www.imdb.com/stats), we can feel confident that this sample is representative of the population, with population in this instance being all movies on IMDB.

It is worth noting that this data does not come from an experiment, but rather an observational study. Therefore, we cannot suggest any causality from our findings. 

* * *

## Part 2: Research question
For this project, we have been given the following guidelines from our boss:

"She is interested in learning what attributes make a movie popular. She is also interested in learning something new about movies. She wants you (sic) team to figure it all out."

We therefore have the first part of our research question already: "What makes a movie popular?". Alongside this, we want to bring something new to the table and impress our boss at Paramount Pictures. We also need to quantify what 'popular' is. For the purposes of our study, we'll assume that a higher IMDB rating means a movie is more popular, as the higher the rating, the more prevalent the movie will be in 'Top X' lists on the website. Therefore, we develop the research question further to state:

"What makes a movie popular on IMDB, in terms of ratings, and is there an association between genre and IMDB rating?"

This helps us understand something new about movies, specifically, if there is a relationship between genre and IMDB rating. While we cannot note any causality in our potential findings, this could be the first step to understanding what makes a 'great' movie on IMDB.

* * *

## Part 3: Exploratory data analysis

Within our research question, we define "popular" as a high IMDB rating. However, we're not sure yet what the *distribution* of ratings looks like. Let's therefore plot this so we can further understand the data we are dealing with:

```{r}
ggplot(data=movies, aes(x=imdb_rating)) + geom_histogram(binwidth=0.2)
```


We can see that the data is left skewed, which should mean that our mean is less than our median. This can be confirmed by reviewing the summary statistics:

```{r}
summary(movies$imdb_rating)
```
Essentially, this means that the median for movie ratings on iMDB is 6.6. This is helpful for us to bear in mind when it comes to our later modelling.


However, what we also need to note here is that IMDB's ratings are defined by users who vote on a movie. Therefore, if a movie could be rated very highly from just 5-6 votes. We therefore also need to understand the distribution of votes across movies:

```{r}
ggplot(data=movies, aes(x=imdb_num_votes)) + geom_histogram(binwidth=10000)
```

Here we have a right-skewed distribution, which should mean that the mean is greater than the median. Again, this can be confirmed by reviewing the summary statistics:

```{r}
summary(movies$imdb_num_votes)
```

We can see that the median here is much less than the mean and given the skew of the data, it makes sense for us to use the median as a measure here.


On our final part of the investigation into voting, we'll also want to take a look at if year of release impacts votes/ratings in any way. As IMDB hasn't been around since the start of cinema, there is some concern that the age of release can impact the amount of votes and average rating a movie has. 

To tackle this, I'm going to add a new variable to the movies dataset, simply examining whether a movie came out in the theatre prior-2000 or during/after. 

```{r}
movies <- mutate(movies, before2000 = ifelse(thtr_rel_year > 2000, "FALSE", "TRUE"))
```

We'll then take a look at the summary statistics for movies prior and post 2000:

#### IMDB Rating Pre 2000
```{r}
prior2000 <- movies %>% filter((before2000 == TRUE))
summary(prior2000$imdb_rating)


```


#### IMDB Number of Votes Pre 2000
```{r}
summary(prior2000$imdb_num_votes)
```


#### IMDB Rating 2000 & Onwards

```{r}
post2000 <- movies %>% filter((before2000 == FALSE))
summary(post2000$imdb_rating)
```
#### IMDB Number of Votes 2000 & Onwards

```{r}
summary(post2000$imdb_num_votes)
```


We can see there aren't huge differences in the rating amounts, which is positive for our later analysis. However, there are some quite stark differences in the medians and means for number of votes for movies prior & post 2000. This is most noticeable when we overlay histograms of each one.

```{r}
ggplot(movies, aes(imdb_num_votes, colour = before2000)) +
  geom_bar(binwidth = 10000)
```

Given that we can assume our boss is commercially going to be interested in more recent movies, for our model, we'll focus in on movies produced on or after the year 2000.

Finally, we also want to take a look at the types of genres we'll be working with. We can easily pull out a list of the genres below:


```{r}
summary(post2000$genre)
```
We have a good spread of genres to work with, but there is some concern that some genres are better represented than others. This can be further confirmed by reviewing a bar chart, where we have abbreviated the genre titles for clarity:

```{r}
ggplot(data=post2000, aes(x=abbreviate(genre))) + geom_bar() +  theme(axis.title = element_text( size=8)) 
```

We can see that Paramount Pictures do have titles within these smaller categories such as Animation and Other, so we would be remiss not include them:

```{r}
ggplot(data=subset(post2000,studio=="Paramount Pictures"), aes(x=genre)) + geom_bar()
```


When working with our model, we will just have to show some caution around genres with very few titles within the model.

We have now gathered enough data to feel confident in how we answer our research question and can proceed to the next step.

* * *

## Part 4: Modeling

We'll now start with our full model, which will include the following metrics:

* genre
* critics_score
* top200_box
* best_pic_nom
* best_actor_win
* best_actress win
* best_dir_win
* mpaa_rating
* audience_rating

We have to be careful of collinearity with the variables provided. For example, there is little point in including critics_rating alongside critics_score, as a high scoring movie will have a rating of fresh, whereas a low will have a rating of rotten. By including both variables, we stand to not learn anything new.

We have included best_pic_nom but not best_pic_win as more movies will be nominated for an Oscar whereas just one will win best picture. Therefore, it makes sense to include a metric which can potentially impact multiple movies as opposed to just a handful per year.

There are also variables which do not make sense for us to include in this analysis. For example, if we wanted to examine if the gender of the first billed actor impacts rating, we could use a Bayesian classifier to identify male/female names from actor1. However, our focus at this point is currently on overall movie variables and in particular, genre. We therefore opt to exclude these variables from our analysis.

Finally, while our focus for the model is on if genre impacts a movie's popularity, we would be foolish not to include other datapoints, such as if a movie's MPAA rating impacts popularity.

Our full model is included below:

```{r}
fullmodel <- lm(imdb_rating ~ genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win + best_dir_win + mpaa_rating , data=post2000)
summary(fullmodel)
```

From this output, we can see the adjusted R-squared is 0.6699. We focus on the adjusted R-squared as opposed to the normal R-squared, as the adjusted R-squared introduces a penalty for each variable we add to the model.

Even from this full model, we can begin to see that genre does impact the rating.


### Model Selection

We know from the course that "the best model is not always the most complicated" and in some instances, irrelevant variables can actually hamper our predictions.

We therefore want to take our full model and distill it down so we can improve the accuracy of our predictions.

As data scientists, our goal will be to improve accuracy for future machine learning applications, so we'll be working towards a model with the highest adjusted R-squared. If we were willing to giveaway a little bit of accuracy for a simpler model, we'd actually choose model selection based on p-values.

Given that we have already created our full model, we'll use backwards selection with adjusted R-squared. For this, we'll start with the full model, drop one variable at a time and record the adjusted R-squared for each smaller model.

#### Full model
```{r}
summary(fullmodel)$adj.r.squared
```

Removing genre:

```{r}
fullmodelalt <- lm(imdb_rating ~  critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win + best_dir_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared

```

Removing critics score:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win + best_dir_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Removing audience rating:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + top200_box + best_pic_nom + best_actor_win + best_actress_win + best_dir_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Removing top 200 box:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + best_pic_nom + best_actor_win + best_actress_win + best_dir_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Removing best_pic_nom

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_actor_win + best_actress_win + best_dir_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Removing best_actor_win

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actress_win + best_dir_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Removing best actress win:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_dir_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Removing best director win:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Removing mpaa rating:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win + best_dir_win , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

#### Step 2
From this output, we can see we have the highest adjusted R-squared when we remove the best director win variable. We therefore drop this variable and proceed with our new model:
```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

We'll therefore continue to check the adjusted R-squared for each new version of the model and drop the variable which, when removed, gives us the highest adjusted R-squared.


Without genre
```{r}
fullmodelalt <- lm(imdb_rating ~  critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without critics score

```{r}
fullmodelalt <- lm(imdb_rating ~  genre  + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without audience rating:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score  + top200_box + best_pic_nom + best_actor_win + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without top 200 box office:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating  + best_pic_nom + best_actor_win + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without best picture nomination:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_actor_win + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without best actor win:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box +  best_actor_win + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```


Without best actress win:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actress_win + mpaa_rating , data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without mpaa rating:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win, data=post2000)
summary(fullmodelalt)$adj.r.squared
```

#### Step 3
We can see here that we get the highest r-squared without MPAA, so we'll drop this variable from our model and continue:

Without genre

```{r}
fullmodelalt <- lm(imdb_rating  ~ critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win, data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without critics score:

```{r}
fullmodelalt <- lm(imdb_rating ~ genre + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win, data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without audience rating:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + top200_box + best_pic_nom + best_actor_win + best_actress_win, data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without top 200 box office:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating  + best_pic_nom + best_actor_win + best_actress_win, data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without best picture nomination:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box  + best_actor_win + best_actress_win, data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without best actor win:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom  + best_actress_win, data=post2000)
summary(fullmodelalt)$adj.r.squared
```

Without best actress win:

```{r}
fullmodelalt <- lm(imdb_rating ~  genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win, data=post2000)
summary(fullmodelalt)$adj.r.squared
```

#### Reduced Model
We cannot beat the adjusted R-squared of the model which excludes MPAA and best director win, so our new model is as follows:

```{r}
newmodel <- lm(imdb_rating  ~ genre + critics_score + audience_rating + top200_box + best_pic_nom + best_actor_win + best_actress_win, data=post2000)
summary(newmodel)
```

Now we have our model, we want to be able to confident that it meets the requirements for multilinear regression. Namely:

1. The residuals of the model are nearly normal

2. The variability of the residuals is nearly constant

3. The residuals are independent

4. Each variable is linearly related to the outcome.

We can check that the residuals of the model are nearly normal with the following plot:

```{r}
ggplot(data = newmodel, aes(sample = .resid)) +
  stat_qq()
```

We can see that the residuals are nearly normal, with some outliers at the extreme ends of the chart. There is a little bit of a curve which we should be wary of, but we will proceed with what we have and express some caution regarding the outliers. 

We also want to check that the variability of the residuals, namely that they are nearly constant and centered around zero, and are independent.

We can check this with both a scatter of the residuals and a histogram:

```{r}
ggplot(data = newmodel, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  xlab("Fitted values") +
  ylab("Residuals")


ggplot(data = newmodel, aes(x = .resid)) +
  geom_histogram(binwidth=0.10) +
  xlab("Residuals")
```

There is some concern that the residuals do dip at the beginning in the scatter plot. However, we do not see a fan shape or anything which indicates an underlying relationship between the variables.

Based on the above and with our reservations in mind, we now have a model which can explain 67.15% of the variability of the response data.

* * *

## Part 5: Prediction

We now want to move onto prediction, specifically, what our model predicts the specific IMDB rating a film might receive.

I'll choose a film released in 2016 (according to IMDB) and create a dataframe with the relevant values needed for my model.


```{r}
underworld <- data.frame(genre = "Action & Adventure", critics_score = 18, audience_rating = "Spilled", top200_box = "no", best_pic_nom = "no", best_actor_win = "no", best_actress_win = "no")
```

```{r}
predict(newmodel, underworld)
```

The model has predicted an IMDB rating of 5.16 for Underworld: Blood Wars. We can also construct a 95% confidence interval around the prediction:

```{r}
predict(newmodel, underworld, interval = "prediction", level = 0.95)
```

The model predicts with 95% confidence that with the following values:

```{r}
summary(underworld)
```

A movie will have a rating of between 3.88 and 6.44. In actual fact, Underworld: Blood Wars has a rating of 5.8.

We gathered our data from the following locations:

* http://www.boxofficemojo.com/movies/?id=underworld5.htm
* https://www.rottentomatoes.com/m/underworld_blood_wars_2017
* http://www.imdb.com/title/tt3717252/?ref_=nv_sr_1

* * *

## Part 6: Conclusion

Now we have gathered all of our data, we need to answer our research question:

"What makes a movie popular on IMDB, in terms of ratings, and is there an association between genre and IMDB rating?"

We can inform our boss that there is a moderately strong relationship between an IMDB rating and the following variables:

* Genre
* Critics Score
* Audience Rating
* Top 200 Box Office
* Best Picture Nomination
* Best Actor Win
* Best Actress Win

and that we have created a model which explains 67.15% of the variability of the response data. Our boss can then use this data for forthcoming movies to model their potential rating on IMDB.

We can also interpret the slopes for genre, for example:

```{r}
summary(newmodel)$coefficients
```

All else held constant, the model predicts that for each unit increase in IMDB score, the score for documentary films will be higher on average by 0.53.

In comparison, all else held constant, the model predicts that for each unit increase in IMDB score, the score for animation films will be lower on average by 0.58.


We can also tell our boss that the following genres, for example, are likely to have a positive impact on ratings:

* Art House & International
* Documentary

We can recommend to our boss that she takes a look at what we'll be producing in these areas, given that from our sample, Paramount Pictures didn't have any Art House or Documentary movies.


We can also tell our boss that the whether or not the director of the movie ever won an Oscar decreased the accuracy of our model, according to adjusted R-squared.. We should make clear to our boss that this doesn't mean she should hire no-name directors (or pass up the chance to work with Spielberg!) but it is an interesting fact about the success of a movie in our model that she might not have known.

Finally, we will also tell our boss about some of the shortcomings of the model. Namely that: While multilinear regression is often the first step in the road to causation, we cannot prove any causality at the moment.